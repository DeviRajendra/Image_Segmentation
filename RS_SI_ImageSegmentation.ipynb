{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RS_SI_ImageSegmentation.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6IupTSMzaHr0"},"source":["# Image Segmentation with Tensorflow using Unet"]},{"cell_type":"code","metadata":{"id":"-W-ZmPE7VZ3M"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuPrGCsRFCeQ"},"source":["## Use Case :\n"," \n"," Remote Sensing Application using Tensorflow\n","\n","    Image segmenation helps to know location of specific object by classifying each pxel in the image. You have been seen image classification which tells the class of the image based on the labels trained in the network. In this case each pixel of image allocates a label and inputs as mask image for training.\n","\n","#### DATASET:\n","Current use case was being developed using the data set \"Inria Aerial Image Labeling Dataset\" https://project.inria.fr/aerialimagelabeling/.\n","\n","\n","After this exercise you will be learning below :\n","\n","     To load the Images and its mask Images\n","\n","     To create the input pipeline using tensorflow dataset \n","\n","     To create the Upsampling layers\n","\n","     To create the downsampling layers\n","\n","     To define the unet model\n","     \n","     To define the Callback functions\n","\n","     To display the Images, masks and its prediction masks"]},{"cell_type":"markdown","metadata":{"id":"TewnIW-EaHr2"},"source":["### Installation required to get pix2pix"]},{"cell_type":"code","metadata":{"id":"DHtBM4GovKaT"},"source":["!pip install git+https://github.com/tensorflow/examples.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5izUtJpaHr7"},"source":["### Import required packages"]},{"cell_type":"code","metadata":{"id":"19JG84aBapND"},"source":["\n","#!pip install pix2pix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsWlq9vFawGr"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yy3Q041nbQBO"},"source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/CV_spec/computer_vision-dev/Img_Seg')\n","%pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VzKryvq4KBdz"},"source":["import os\n","import cv2\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","from pix2pix import pix2pix\n","\n","from IPython.display import clear_output\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"luh4YUWPaHr_"},"source":["### Read the train Images and its masks"]},{"cell_type":"code","metadata":{"id":"eTqOna36JofL"},"source":["# Reading images\n","NumTrainImags=10\n","NumTestImags=10\n","resize=320\n","\n","# Train Set: Image and Mask (Ground Truth)\n","\n","TRAIN_IMAGE_DIR_PATH = 'AerialImageDataset/train/images'\n","TRAIN_MASK_DIR_PATH = 'AerialImageDataset/train/gt'\n","\n","# create list of PATHS\n","train_image_paths = [os.path.join(TRAIN_IMAGE_DIR_PATH, x) for x in sorted(os.listdir(TRAIN_IMAGE_DIR_PATH)) if x.endswith('.tif')]\n","train_mask_paths = [os.path.join(TRAIN_MASK_DIR_PATH, x) for x in sorted(os.listdir(TRAIN_MASK_DIR_PATH)) if x.endswith('.tif')]\n","\n","\n","train_img_data_list=[]\n","for img in train_image_paths[:NumTrainImags]:\n","        train_input_img=cv2.imread(img)\n","        train_input_img_resize=cv2.resize(train_input_img,(resize, resize))\n","        train_img_data_list.append(train_input_img_resize)\n","      \n","      \n","train_mask_data_list=[]\n","for img in train_mask_paths[:NumTrainImags]:\n","        train_mask_img=cv2.imread(img)\n","        train_mask_img_resize=cv2.resize(train_mask_img,(resize, resize))\n","        train_mask_img_resize=cv2.cvtColor(train_mask_img_resize, cv2.COLOR_BGR2GRAY)\n","        train_mask_data_list.append(train_mask_img_resize)\n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqlKvohfaHsD"},"source":["### Read the test Images and its masks"]},{"cell_type":"code","metadata":{"id":"PPuhJ66taHsE"},"source":["# Test Set: Image and Mask (Ground Truth)\n","\n","TEST_IMAGE_DIR_PATH = 'AerialImageDataset/test/images'\n","TEST_MASK_DIR_PATH = 'AerialImageDataset/test/gt'\n","\n","# create list of PATHS\n","test_image_paths = [os.path.join(TEST_IMAGE_DIR_PATH, x) for x in sorted(os.listdir(TEST_IMAGE_DIR_PATH)) if x.endswith('.tif')]\n","test_mask_paths = [os.path.join(TEST_MASK_DIR_PATH, x) for x in sorted(os.listdir(TEST_MASK_DIR_PATH)) if x.endswith('.tif')]\n","\n","\n","test_img_data_list=[]\n","for img in test_image_paths[:NumTestImags]:\n","        test_input_img=cv2.imread(img)\n","        test_input_img_resize=cv2.resize(test_input_img,(resize, resize))\n","        test_img_data_list.append(test_input_img_resize)\n","      \n","      \n","test_mask_data_list=[]\n","for img in test_mask_paths[:NumTestImags]:\n","        test_mask_img=cv2.imread(img)\n","        test_mask_img_resize=cv2.resize(test_mask_img,(resize, resize))\n","        test_mask_img_resize=cv2.cvtColor(test_mask_img_resize, cv2.COLOR_BGR2GRAY)\n","        test_mask_data_list.append(test_mask_img_resize)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6lkLT38YaHsH"},"source":["### Convert to numpy array and datatype to float32"]},{"cell_type":"code","metadata":{"id":"kZZ8t4AQ9Cs2"},"source":["#Train Set\n","train_img_data = np.array(train_img_data_list)\n","train_img_data = train_img_data.astype('float32')\n","\n","train_mask_data = np.array(train_mask_data_list)\n","train_mask_data = train_mask_data.astype('float32')\n","train_mask_data = train_mask_data[..., np.newaxis]\n","\n","# Test Set\n","test_img_data = np.array(test_img_data_list)\n","test_img_data = test_img_data.astype('float32')\n","\n","test_mask_data = np.array(test_mask_data_list)\n","test_mask_data = test_mask_data.astype('float32')\n","test_mask_data = test_mask_data[..., np.newaxis]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Smocj-BYaHsM"},"source":["### Get the shape of train and test Images"]},{"cell_type":"code","metadata":{"id":"gDAZ4qR19da2"},"source":["print(train_img_data.shape)\n","print(train_mask_data.shape)\n","print(test_img_data.shape)\n","print(test_mask_data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8awehC4waHsS"},"source":["### View the sample original image"]},{"cell_type":"code","metadata":{"id":"8WWvxWmaAIUb"},"source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(8,8))\n","plt.imshow(train_img_data_list[0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZNK4z_W1aHsV"},"source":["### View the sample mask image"]},{"cell_type":"code","metadata":{"id":"iAIIAq0WogCo"},"source":["plt.figure(figsize=(8,8))\n","plt.imshow(train_mask_data_list[0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_LoLyMucaHsZ"},"source":["### Define the required training Variables"]},{"cell_type":"code","metadata":{"id":"tOcdWQhhGX_D"},"source":["TRAIN_LENGTH = NumTrainImags\n","BATCH_SIZE = 5\n","BUFFER_SIZE = 10\n","STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCGHVl4caHsd"},"source":["### Define the required functions"]},{"cell_type":"code","metadata":{"id":"zhNVC_2Nb6Nn"},"source":["inp_im = train_img_data_list[0]\n","inp_mask = train_mask_data_list[0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tS5H0c6adR9T"},"source":["\n","inp_mask.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LviAJZp1igTc"},"source":["'''\n","This function is used to normalize the image and its masks\n","Input: Image and its mask\n","Output: Normalized Image and its masks\n","'''\n","def normalize(input_image, input_mask):\n","  input_image = tf.cast(input_image, tf.float32)/resize - 1\n","  input_mask = input_mask/255\n","  return input_image, input_mask\n","\n","'''\n","This function is used to call the normalize function on train data\n","Input: Image and its mask\n","Output: Normalized Image and its masks\n","'''\n","@tf.function\n","def load_image_train(image, mask):\n","    \n","    image, mask = normalize(image, mask)\n","\n","    return image, mask\n","\n","'''\n","This function is used to normalize the image and its masks on test data\n","Input: Image and its mask\n","Output: Normalized Image and its masks\n","'''\n","def load_image_test(image, mask):\n","\n","  image, mask = normalize(image, mask)\n","\n","  return image, mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxqYwtJWaHsg"},"source":["### Using Tensorflow Dataset for the input pipeline"]},{"cell_type":"code","metadata":{"id":"YRrvqOdn6zl7"},"source":["# Create the tensorflow dataset using .from_tensor_slices\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_img_data, train_mask_data))\n","\n","# Use the map function to apply the parallization\n","train_dataset = train_dataset.map(load_image_train, \n","                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","# To shuffle the data\n","train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n","\n","# To define the Buffer size\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","train_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E76XARlOaHsk"},"source":["### Apply the input pipeline for the test dataset"]},{"cell_type":"code","metadata":{"id":"QnuDK4Q2Rt9e"},"source":["test_dataset = tf.data.Dataset.from_tensor_slices((test_img_data, test_mask_data))\n","test_dataset = test_dataset.map(load_image_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","test_dataset = test_dataset.cache().batch(1)\n","\n","test_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eq-TEZXFaHso"},"source":["### Define the function to display the Image,mask and its prediction"]},{"cell_type":"code","metadata":{"id":"1crkFrg0j6WZ"},"source":["'''\n","This function is used to display the Image , mask and its predicted mask\n","Input: List of Image , mask and its predicted mask\n","Output: display of Image, mask and its predicted mask \n","'''\n","def display(display_list):\n","  plt.figure(figsize=(15, 15))\n","\n","  title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","    plt.axis('off')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDV2z9HtkM2a"},"source":["for image, mask in train_dataset.take(1):\n","  sample_image, sample_mask = image, mask\n","display([sample_image[0], sample_mask[0]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-_FL0K_aHsv"},"source":["## Define the Unet Model "]},{"cell_type":"code","metadata":{"id":"VIlxghLDaHsv"},"source":["from IPython.display import Image\n","Image('unet.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOx_z9dRaHsy"},"source":["### Define the upsampling layers"]},{"cell_type":"code","metadata":{"id":"UGEGnJDcaHsy"},"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=[resize, resize, 3], include_top=False)\n","base_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvORKcdSkYDn"},"source":["# Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',   # 64x64\n","    'block_3_expand_relu',   # 32x32\n","    'block_6_expand_relu',   # 16x16\n","    'block_13_expand_relu',  # 8x8\n","    'block_16_project',      # 4x4\n","]\n","layers = [base_model.get_layer(name).output for name in layer_names]\n","\n","# Create the feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n","\n","down_stack.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-W748JDIaHs4"},"source":["### Define the downsampling layers"]},{"cell_type":"code","metadata":{"id":"4YsjIqyrka1Q"},"source":["up_stack = [\n","    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n","    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n","    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n","    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zB9or0TkPig"},"source":["OUTPUT_CHANNELS = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ui0G_Iv9aHs_"},"source":["### Define the Unet model using upsampling and downsampling layers"]},{"cell_type":"code","metadata":{"id":"gG-2-aRgcz0c"},"source":["\n","inputs = tf.keras.layers.Input(shape=[resize, resize, 3])\n","x = inputs\n","# Downsampling through the model\n","skips = down_stack(x)\n","skips\n","#x = skips[-1]\n","#print(x)\n","# skips = reversed(skips[:-1])\n","# skips"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9my8FmPjkfPj"},"source":["'''\n","This function is used to define the unet model\n","Input: no of output filteres\n","Output: Unet model \n","'''\n","def unet_model(output_channels):\n","\n","  # This is the last layer of the model\n","  last = tf.keras.layers.Conv2DTranspose(\n","      output_channels, 3, strides=2,\n","      padding='same', activation='softmax')  #64x64 -> 128x128\n","\n","  inputs = tf.keras.layers.Input(shape=[resize, resize, 3])\n","  x = inputs\n","\n","  # Downsampling through the model\n","  skips = down_stack(x)\n","  x = skips[-1]\n","  skips = reversed(skips[:-1])\n","\n","  # Upsampling and establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    concat = tf.keras.layers.Concatenate()\n","    x = concat([x, skip])\n","\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X524qU6XaHtC"},"source":["### Create the model and compile the model"]},{"cell_type":"code","metadata":{"id":"QjtCQEu1k8zY"},"source":["model = unet_model(OUTPUT_CHANNELS)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RWtWgQx9aHtH"},"source":["### Function to reshape the predicted mask"]},{"cell_type":"code","metadata":{"id":"U-Dsv2E2k_c5"},"source":["'''\n","This function is used to reshape the predicted masks \n","Input: Predicted masks\n","Output: Reshaped predicted masks such that the last channel changes to 1 \n","'''\n","def create_mask(pred_mask):\n","    #Calling tf.argmax on with axis=-1 make the tensor loose the last channel \n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    \n","    #This is added back as a singleton channel via tf.newaxis\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qz3SkrETaHtL"},"source":["### Function to predict the test image and display its predicted masks"]},{"cell_type":"code","metadata":{"id":"-34fxM9lVKKc"},"source":["'''\n","This function is used to predict the test image and call the display function\n","Input: Test image\n","Output: display of Image, mask and its predicted mask \n","'''\n","def show_predictions(dataset=None, num=1):\n","  if dataset:\n","    for image, mask in dataset.take(num):\n","      pred_mask = model.predict(image)\n","      display([image[0], mask[0], create_mask(pred_mask)])\n","  else:\n","    display([sample_image[0], sample_mask[0], create_mask(model.predict(sample_image))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3pL1h-BlF1r"},"source":["show_predictions()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEUIUdyzaHtS"},"source":["### Class to define the callback function which displays the predicted masks after each epoch"]},{"cell_type":"code","metadata":{"id":"6x09s_gvlJxq"},"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    clear_output(wait=True)\n","    show_predictions()\n","    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5sZTE_JCaHtV"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"L24WQNO8lOJr"},"source":["EPOCHS = 10#30\n","\n","model_history = model.fit(train_dataset, epochs=EPOCHS, callbacks=[DisplayCallback()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qPMrdIScaHte"},"source":["### Display the loss at each epoch"]},{"cell_type":"code","metadata":{"id":"hEm3ioG7lQ1E"},"source":["loss = model_history.history['loss']\n","epochs = range(EPOCHS)\n","\n","plt.figure()\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.title('Training Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Value')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Exf5oTFaHth"},"source":["### Call the show_predictions function to display the test images, its masks and its predicted masks"]},{"cell_type":"code","metadata":{"id":"wMsoKWg-lerb","scrolled":true},"source":["show_predictions(test_dataset, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gmWQ4SOaHtk"},"source":["Ref\n","    \n","    https://www.tensorflow.org/tutorials"]}]}